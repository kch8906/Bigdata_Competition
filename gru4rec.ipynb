{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a73de48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/changhyun/workspace/Bigdata_Competition/last\n"
     ]
    }
   ],
   "source": [
    "%cd last/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "257adde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 730291/730291 [00:21<00:00, 33558.87it/s]\n",
      "100%|████████████████████████████████| 730290/730290 [00:21<00:00, 34142.87it/s]\n",
      "100%|████████████████████████████████| 730291/730291 [00:22<00:00, 32566.20it/s]\n",
      "100%|████████████████████████████████| 730291/730291 [00:22<00:00, 33048.46it/s]\n",
      "100%|████████████████████████████████| 730290/730290 [00:21<00:00, 34321.65it/s]\n",
      "100%|████████████████████████████████| 730290/730290 [00:22<00:00, 33177.44it/s]\n"
     ]
    }
   ],
   "source": [
    "!python preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3347ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class SessionDataset:\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.df = df.sort_values(by = ['session', 'timestamp']).reset_index(drop = True) # session (int) | timestamp (int) | item (string)\n",
    "        self.offsets = np.concatenate((np.zeros(1, dtype = np.int32), self.df.groupby('session').size().cumsum().values)) # indices in df where the sessions start\n",
    "        self.n_sessions = len(self.offsets) - 1\n",
    "\n",
    "        self.item_to_id = {item : i for i, item in enumerate(self.df.item.unique())}\n",
    "\n",
    "        self.n_items = len(self.item_to_id)\n",
    "\n",
    "    def item_to_one_hot(self, item):\n",
    "\n",
    "        return tf.one_hot(self.item_to_id[item], depth = self.n_items)\n",
    "\n",
    "    def extract_session(self, i, one_hot_encoded = True):\n",
    "\n",
    "        session = self.df[self.offsets[i]:self.offsets[i+1]].copy()\n",
    "        if one_hot_encoded:\n",
    "            session.loc[:, 'item'] = session.item.apply(lambda x : self.item_to_one_hot(x))\n",
    "        return session.item.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40dee12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = (BATCH_SIZE, n_classes)   one-hot representations of the target items (ground truths)\n",
    "# y_pred = (BATCH_SIZE, n_classes)   model output = next item scores (logits) for each item in the batch\n",
    "\n",
    "sampling = False\n",
    "\n",
    "if sampling: # = the negative items considered in the loss computation are those within the same batch\n",
    "    \n",
    "    def BPR(y_true, y_pred):\n",
    "        to_lookup = tf.argmax(y_true, axis = 1)   # = indices of the target items\n",
    "        scores = tf.nn.embedding_lookup(tf.transpose(y_pred), to_lookup)  # embedding_lookup is the same as \"extract_rows\". In this way, the positive items end up on the diagonal\n",
    "        return tf.reduce_mean(-tf.math.log(tf.nn.sigmoid(tf.linalg.diag_part(scores) - scores)))\n",
    "\n",
    "    def TOP1(y_true, y_pred):\n",
    "        to_lookup = tf.argmax(y_true, axis = 1)\n",
    "        scores = tf.nn.embedding_lookup(tf.transpose(y_pred), to_lookup)\n",
    "        diag_scores = tf.linalg.diag_part(scores)\n",
    "        loss_by_sample  = tf.reduce_mean(tf.nn.sigmoid(scores - diag_scores) + tf.nn.sigmoid(tf.square(scores)), axis = 0)\n",
    "        loss_by_sample -= tf.nn.sigmoid(tf.square(diag_scores)) / tf.reduce_sum(tf.ones_like(diag_scores)) # only sigmoids of squares of negative items had to be added: remove those of positive items\n",
    "        return tf.reduce_mean(loss_by_sample)\n",
    "\n",
    "else: # = consider all negative items in the loss computation (only makes sense if the number of items is small, like the same order as the batch size)\n",
    "\n",
    "    def BPR(y_true, y_pred):  # both inputs have shape (BATCH_SIZE, n_classes)\n",
    "        _y_pred = tf.expand_dims(y_pred, axis = -1)  # (BATCH_SIZE, n_classes, 1) \n",
    "        mat = tf.matmul(tf.expand_dims(tf.ones_like(y_true), -1), tf.expand_dims(y_true, axis = 1)) # (BATCH_SIZE, n_classes, 1) x (BATCH_SIZE, 1, n_classes) = (BATCH_SIZE, n_classes, n_classes)\n",
    "        score_diffs = tf.matmul(mat, _y_pred) # (BATCH_SIZE, n_classes, n_classes) x (BATCH_SIZE, n_classes, 1) = (BATCH_SIZE, n_classes, 1)\n",
    "        score_diffs = tf.squeeze(score_diffs - _y_pred, -1) # (BATCH_SIZE, n_classes)\n",
    "        return -tf.reduce_sum(tf.math.log(tf.nn.sigmoid(score_diffs)))\n",
    "\n",
    "    def TOP1(y_true, y_pred):\n",
    "        _y_pred = tf.expand_dims(y_pred, axis = -1)  # (BATCH_SIZE, n_classes) ---> (BATCH_SIZE, n_classes, 1) \n",
    "        mat = tf.matmul(tf.expand_dims(tf.ones_like(y_true), -1), tf.expand_dims(y_true, axis = 1)) # (BATCH_SIZE, n_classes, 1) x (BATCH_SIZE, 1, n_classes) --> (BATCH_SIZE, n_classes, n_classes)\n",
    "        score_diffs = tf.matmul(mat, _y_pred) # (BATCH_SIZE, n_classes, n_classes) x (BATCH_SIZE, n_classes, 1) --> (BATCH_SIZE, n_classes, 1)\n",
    "        score_diffs = tf.squeeze(score_diffs - _y_pred, -1) # (BATCH_SIZE, n_classes)\n",
    "        loss_by_sample = tf.reduce_sum(tf.nn.sigmoid(tf.square(y_pred)), axis = -1) + \\\n",
    "                          tf.reduce_sum(tf.sigmoid(-score_diffs), axis = -1) + \\\n",
    "                        -tf.squeeze(tf.squeeze(tf.nn.sigmoid(tf.square(tf.matmul(tf.expand_dims(y_true, 1), _y_pred))), -1), -1)\n",
    "        return tf.reduce_sum(loss_by_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5655b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gru4Rec:\n",
    "\n",
    "    def __init__(self, n_classes, n_layers = 1, n_hidden = 64, loss = TOP1, batch_size = 8):\n",
    "\n",
    "        self.n_classes  = n_classes   # = number of items\n",
    "\n",
    "        self.n_layers = n_layers  # number of stacked GRU layers\n",
    "        self.n_hidden = n_hidden  # dimension of GRU cell's hidden state\n",
    "        self.loss     = loss\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "\n",
    "        model = tf.keras.models.Sequential()\n",
    "        for i in range(self.n_layers):\n",
    "            model.add(tf.keras.layers.GRU(name = 'GRU_{}'.format(i+1),\n",
    "                                          units      = self.n_hidden, \n",
    "                                          activation = 'relu', \n",
    "                                          stateful   = True,\n",
    "                                          return_sequences = (i < self.n_layers - 1)))\n",
    "        model.add(tf.keras.layers.Dense(units = self.n_classes, activation = 'linear'))   # class logits\n",
    "\n",
    "        # track top 3 accuracy (= how often the true item is among the top 3 recommended)\n",
    "        top3accuracy = lambda y_true, y_pred: tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k = 3)\n",
    "        top3accuracy.__name__ = 'top3_accuracy'\n",
    "        model.compile(loss = self.loss, optimizer = 'adam', metrics = ['accuracy', top3accuracy])\n",
    "\n",
    "        model.build(input_shape = (self.batch_size, 1, self.n_classes))\n",
    "        print(model.summary())\n",
    "\n",
    "        return model\n",
    "\n",
    "    def _reset_hidden(self, i):\n",
    "\n",
    "        for nl, layer in enumerate(self.model.layers):   # session has changed: reset corresponding hidden state\n",
    "            if self._is_GRU_layer(layer) and layer.states[0] is not None:\n",
    "                hidden_updated = layer.states[0].numpy()\n",
    "                hidden_updated[i, :] = 0.\n",
    "                self.model.layers[nl].reset_states(hidden_updated)\n",
    "\n",
    "    def _is_GRU_layer(self, layer):\n",
    "\n",
    "        return layer.name.startswith('GRU_')\n",
    "\n",
    "    def train_batch_generator(self, dataset):  # session | item | timestamp\n",
    "        # generates batches of training data X, y = session item, next session item\n",
    "\n",
    "        assert dataset.n_sessions > self.batch_size, \"Training set is too small. Reduce batch size or collect more training data\"\n",
    "        ixs = np.arange(dataset.n_sessions)\n",
    "\n",
    "        stacks = [[]] * self.batch_size   # stacks containing batch_size REVERSED (pieces of) sessions at once. Will be emptied progressively\n",
    "        next_session_id = 0\n",
    "\n",
    "        X, y = np.empty(shape = (self.batch_size, 1, self.n_classes)), np.empty(shape = (self.batch_size, self.n_classes))    \n",
    "        while True:\n",
    "            X[:], y[:] = None, None\n",
    "            for i in range(self.batch_size): # fill in X, y (current batch)\n",
    "                # 1. If stack i is empty (only happens at first round) or has only one element: fill it with a new session\n",
    "                if len(stacks[i]) <= 1:\n",
    "                    if next_session_id >= dataset.n_sessions: # no more sessions available: shuffle sessions and restart\n",
    "                        np.random.shuffle(ixs)\n",
    "                        next_session_id = 0\n",
    "                    while not len(stacks[i]) >= 2:   # ignore sessions with only one element (cannot contribute to the training)\n",
    "                        stacks[i] = dataset.extract_session(ixs[next_session_id])[::-1]  # the data does not have to be all in memory at the same time: we could e.g. load a session at once\n",
    "                        next_session_id += 1\n",
    "                    self._reset_hidden(i)   # if session changes, the corresponding hidden state must be reset\n",
    "                # 2. Stack i is now valid: set input + target variables\n",
    "                X[i, 0] = stacks[i].pop()\n",
    "                y[i]    = stacks[i][-1]\n",
    "\n",
    "            yield tf.constant(X, dtype = tf.float32), tf.constant(y, dtype = tf.float32)\n",
    "\n",
    "    def fit(self, dataset, steps_per_epoch = 10000, epochs = 5):\n",
    "\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath = \"gru-chkpt-{epoch:02d}.hdf5\")\n",
    "        self.model.fit_generator(generator       = self.train_batch_generator(dataset), \n",
    "                                 steps_per_epoch = steps_per_epoch, \n",
    "                                 epochs          = epochs,\n",
    "                                 callbacks       = [checkpoint], \n",
    "                                 shuffle         = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bb6644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test\n",
      "   session      item\n",
      "0        0        완구\n",
      "1        1      패션잡화\n",
      "2        2        과자\n",
      "3        3        과자\n",
      "4        4  화장품/뷰티케어\n",
      "\n",
      "y_test\n",
      "   session     item\n",
      "0        0       완구\n",
      "1        1     여성의류\n",
      "2        2       음료\n",
      "3        3      축산물\n",
      "4        4  테넌트/음식점\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('../../dataset/big_comp/convert_time_df.csv', sep='\\t')\n",
    "\n",
    "columns = ['session']\n",
    "for i in columns:\n",
    "    globals()[f'encoder_{i}'] = LabelEncoder()\n",
    "    df[i] = globals()[f'encoder_{i}'].fit_transform(df[i]) \n",
    "\n",
    "df = df.sort_values(by = ['session', 'timestamp']).reset_index(drop = True)\n",
    "\n",
    "offsets = np.concatenate((np.zeros(1, dtype = np.int32), df.groupby('session').size().cumsum().values))\n",
    "\n",
    "dataset_train = SessionDataset(df.iloc[~df.index.isin(offsets[1:] - 1)])  # training set: remove last element from each session\n",
    "\n",
    "# Test set: x = penultimate item in each session, y = last item in each session\n",
    "X_test = df.iloc[offsets[1:] - 2][['session', 'item']].sort_values('session').reset_index(drop = True)\n",
    "y_test = df.iloc[offsets[1:] - 1][['session', 'item']].sort_values('session').reset_index(drop = True)\n",
    "\n",
    "print(\"X_test\")\n",
    "print(X_test.head())\n",
    "print('')\n",
    "print(\"y_test\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6a6af7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer GRU_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " GRU_1 (GRU)                 (8, 64)                   24192     \n",
      "                                                                 \n",
      " dense (Dense)               (8, 60)                   3900      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,092\n",
      "Trainable params: 28,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 03:52:17.484069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-07 03:52:17.512622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-07 03:52:17.512775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-07 03:52:17.513290: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-07 03:52:17.513657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-07 03:52:17.513788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-07 03:52:17.513906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-07 03:52:17.905186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-07 03:52:17.905348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-07 03:52:17.905475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-07 03:52:17.905577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3874 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 31s 3ms/step - loss: 385.1189 - accuracy: 0.1716 - top3accuracy: 0.3500\n",
      "Epoch 2/5\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 365.2920 - accuracy: 0.2436 - top3accuracy: 0.4309\n",
      "Epoch 3/5\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 360.7752 - accuracy: 0.2596 - top3accuracy: 0.4422\n",
      "Epoch 4/5\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 359.2264 - accuracy: 0.2689 - top3accuracy: 0.4609\n",
      "Epoch 5/5\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 360.1653 - accuracy: 0.2697 - top3accuracy: 0.4520\n"
     ]
    }
   ],
   "source": [
    "g4r = Gru4Rec(n_classes = dataset_train.n_items)\n",
    "g4r.fit(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea212c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_states = np.empty(shape = (dataset_train.n_sessions, g4r.n_layers, g4r.n_hidden)) # final states will be stored here\n",
    "final_states[:] = None\n",
    "done = [False] * dataset_train.n_sessions   # keep track of the sessions for which the last state has already been calculated\n",
    "\n",
    "stacks = [dataset_train.extract_session(i)[::-1] for i in range(g4r.batch_size)]\n",
    "next_session_id = g4r.batch_size\n",
    "batch_idx_to_session = np.arange(g4r.batch_size)   # keep track of which session is in each batch element\n",
    "X = np.empty(shape = (g4r.batch_size, 1, g4r.n_classes))\n",
    "\n",
    "g4r.model.reset_states()    # all hidden states set to 0 (starting point)\n",
    "\n",
    "n_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4097034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25884"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.n_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338118f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "final_states = np.empty(shape = (dataset_train.n_sessions, g4r.n_layers, g4r.n_hidden)) # final states will be stored here\n",
    "final_states[:] = None\n",
    "done = [False] * dataset_train.n_sessions   # keep track of the sessions for which the last state has already been calculated\n",
    "\n",
    "stacks = [dataset_train.extract_session(i)[::-1] for i in range(g4r.batch_size)]\n",
    "next_session_id = g4r.batch_size\n",
    "batch_idx_to_session = np.arange(g4r.batch_size)   # keep track of which session is in each batch element\n",
    "X = np.empty(shape = (g4r.batch_size, 1, g4r.n_classes))\n",
    "\n",
    "g4r.model.reset_states()    # all hidden states set to 0 (starting point)\n",
    "\n",
    "n_done = 0\n",
    "\n",
    "while n_done < dataset_train.n_sessions:\n",
    "    for i in range(g4r.batch_size):\n",
    "        while len(stacks[i]) == 1:  # stack i is at the end\n",
    "            if not done[batch_idx_to_session[i]]:\n",
    "                # save final hidden state\n",
    "                final_states[batch_idx_to_session[i], :] = np.array([layer.states[0][i, :] for layer in g4r.model.layers if g4r._is_GRU_layer(layer)])\n",
    "                done[batch_idx_to_session[i]] = True\n",
    "                n_done += 1\n",
    "                print(str(round(n_done/25884*100,1))+\"% is completed.\")\n",
    "#                 if n_done % 100 == 0:\n",
    "#                     print(f\"Progress: {n_done} / {dataset_train.n_sessions}\")\n",
    "            if next_session_id >= dataset_train.n_sessions: # restart from the beginning (just to reach required batch size)\n",
    "                next_session_id = 0\n",
    "            stacks[i] = dataset_train.extract_session(next_session_id)[::-1]\n",
    "            batch_idx_to_session[i] = next_session_id\n",
    "            next_session_id += 1\n",
    "            g4r._reset_hidden(i)   # session has changed --> reset corresponding hidden state\n",
    "        X[i, 0] = stacks[i].pop()\n",
    "\n",
    "    _ = g4r.model.predict(X)   # hidden states get updated when \"predict\" is called\n",
    "\n",
    "print(\"All final hidden states calculated\")\n",
    "np.save('../../dataset/big_comp/final_states.npy', final_states, allow_pickle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca61c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_states = np.load('../../dataset/big_comp/final_states.npy')\n",
    "\n",
    "g4r.model.reset_states()\n",
    "\n",
    "rem = dataset_train.n_sessions % g4r.batch_size\n",
    "if rem > 0:\n",
    "    X_test = pd.concat((X_test, X_test[:(g4r.batch_size - rem)]), axis = 0)\n",
    "\n",
    "# Calculate next item predictions for all sessions\n",
    "y_pred = np.empty(shape = (dataset_train.n_sessions, g4r.n_classes))\n",
    "y_pred[:] = None\n",
    "X = np.empty(shape = (g4r.batch_size, 1, g4r.n_classes))\n",
    "for batch_id in range(dataset_train.n_sessions // g4r.batch_size):\n",
    "    # X contains the penultimate item in the session (= last item in the training set)\n",
    "    X[:] = None\n",
    "    for i in range(g4r.batch_size):\n",
    "        X[i, :] = dataset_train.item_to_one_hot(X_test.iloc[batch_id * g4r.batch_size + i]['item'])\n",
    "    # set hidden states equal to final hidden states for sessions in the batch\n",
    "    nlg = 0\n",
    "    for nl, layer in enumerate(g4r.model.layers):\n",
    "        if g4r._is_GRU_layer(layer):\n",
    "            g4r.model.layers[nl].reset_states(final_states[batch_id * g4r.batch_size : (batch_id + 1) * g4r.batch_size, nlg, :])\n",
    "            nlg += 1\n",
    "    # objective: predict last element in the session\n",
    "    y_pred[batch_id * g4r.batch_size : (batch_id + 1) * g4r.batch_size, :] = g4r.model.predict(X)[:g4r.batch_size]\n",
    "\n",
    "y_pred = tf.constant(y_pred[:dataset_train.n_sessions], dtype = tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "36b57881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.101400</td>\n",
       "      <td>5.122470</td>\n",
       "      <td>0.411462</td>\n",
       "      <td>-0.236007</td>\n",
       "      <td>-0.024931</td>\n",
       "      <td>-0.231721</td>\n",
       "      <td>5.983501</td>\n",
       "      <td>0.489373</td>\n",
       "      <td>0.210659</td>\n",
       "      <td>0.313644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013549</td>\n",
       "      <td>0.194592</td>\n",
       "      <td>-0.138011</td>\n",
       "      <td>-0.050456</td>\n",
       "      <td>-0.198736</td>\n",
       "      <td>-0.213913</td>\n",
       "      <td>-0.187095</td>\n",
       "      <td>-0.094436</td>\n",
       "      <td>-0.199338</td>\n",
       "      <td>-0.197980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.134058</td>\n",
       "      <td>1.717681</td>\n",
       "      <td>-0.343599</td>\n",
       "      <td>0.297462</td>\n",
       "      <td>6.539805</td>\n",
       "      <td>-0.081693</td>\n",
       "      <td>4.824500</td>\n",
       "      <td>0.022874</td>\n",
       "      <td>0.056690</td>\n",
       "      <td>-0.091561</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179814</td>\n",
       "      <td>-0.210738</td>\n",
       "      <td>-0.313608</td>\n",
       "      <td>-0.103755</td>\n",
       "      <td>-0.234412</td>\n",
       "      <td>-0.214502</td>\n",
       "      <td>-0.186226</td>\n",
       "      <td>-0.194537</td>\n",
       "      <td>-0.225704</td>\n",
       "      <td>-0.222353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.108491</td>\n",
       "      <td>9.877229</td>\n",
       "      <td>-0.307102</td>\n",
       "      <td>0.014491</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>-0.102377</td>\n",
       "      <td>12.490325</td>\n",
       "      <td>0.011585</td>\n",
       "      <td>0.356762</td>\n",
       "      <td>0.051139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092662</td>\n",
       "      <td>-0.006177</td>\n",
       "      <td>-0.102056</td>\n",
       "      <td>-0.141185</td>\n",
       "      <td>-0.150112</td>\n",
       "      <td>-0.049161</td>\n",
       "      <td>-0.328302</td>\n",
       "      <td>-0.163079</td>\n",
       "      <td>-0.139322</td>\n",
       "      <td>-0.142054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.097103</td>\n",
       "      <td>7.277634</td>\n",
       "      <td>0.665289</td>\n",
       "      <td>-0.202129</td>\n",
       "      <td>0.387593</td>\n",
       "      <td>0.094024</td>\n",
       "      <td>11.349756</td>\n",
       "      <td>1.859478</td>\n",
       "      <td>3.956362</td>\n",
       "      <td>-0.248531</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166493</td>\n",
       "      <td>-0.066305</td>\n",
       "      <td>-0.053265</td>\n",
       "      <td>-0.210834</td>\n",
       "      <td>-0.063536</td>\n",
       "      <td>-0.160048</td>\n",
       "      <td>-0.087788</td>\n",
       "      <td>-0.057035</td>\n",
       "      <td>-0.149206</td>\n",
       "      <td>-0.148674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.026675</td>\n",
       "      <td>1.723083</td>\n",
       "      <td>-0.112334</td>\n",
       "      <td>-0.112589</td>\n",
       "      <td>0.352426</td>\n",
       "      <td>-0.153636</td>\n",
       "      <td>2.945801</td>\n",
       "      <td>-0.284290</td>\n",
       "      <td>0.030442</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191590</td>\n",
       "      <td>-0.251919</td>\n",
       "      <td>-0.098760</td>\n",
       "      <td>-0.208515</td>\n",
       "      <td>-0.168009</td>\n",
       "      <td>-0.134835</td>\n",
       "      <td>-0.077329</td>\n",
       "      <td>-0.169855</td>\n",
       "      <td>-0.120925</td>\n",
       "      <td>-0.121390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25879</th>\n",
       "      <td>-0.244383</td>\n",
       "      <td>4.529177</td>\n",
       "      <td>2.099071</td>\n",
       "      <td>-0.023050</td>\n",
       "      <td>-0.196272</td>\n",
       "      <td>-0.165463</td>\n",
       "      <td>3.440201</td>\n",
       "      <td>0.716204</td>\n",
       "      <td>1.595793</td>\n",
       "      <td>0.310500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342207</td>\n",
       "      <td>-0.247778</td>\n",
       "      <td>-0.122210</td>\n",
       "      <td>-0.209082</td>\n",
       "      <td>-0.136593</td>\n",
       "      <td>-0.066616</td>\n",
       "      <td>-0.083899</td>\n",
       "      <td>-0.005069</td>\n",
       "      <td>-0.099946</td>\n",
       "      <td>-0.089550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25880</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25881</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25882</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25883</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25884 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5          6   \\\n",
       "0     -0.101400  5.122470  0.411462 -0.236007 -0.024931 -0.231721   5.983501   \n",
       "1      6.134058  1.717681 -0.343599  0.297462  6.539805 -0.081693   4.824500   \n",
       "2      0.108491  9.877229 -0.307102  0.014491  0.023762 -0.102377  12.490325   \n",
       "3     -0.097103  7.277634  0.665289 -0.202129  0.387593  0.094024  11.349756   \n",
       "4     -0.026675  1.723083 -0.112334 -0.112589  0.352426 -0.153636   2.945801   \n",
       "...         ...       ...       ...       ...       ...       ...        ...   \n",
       "25879 -0.244383  4.529177  2.099071 -0.023050 -0.196272 -0.165463   3.440201   \n",
       "25880       NaN       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "25881       NaN       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "25882       NaN       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "25883       NaN       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "\n",
       "             7         8         9   ...        50        51        52  \\\n",
       "0      0.489373  0.210659  0.313644  ... -0.013549  0.194592 -0.138011   \n",
       "1      0.022874  0.056690 -0.091561  ... -0.179814 -0.210738 -0.313608   \n",
       "2      0.011585  0.356762  0.051139  ... -0.092662 -0.006177 -0.102056   \n",
       "3      1.859478  3.956362 -0.248531  ... -0.166493 -0.066305 -0.053265   \n",
       "4     -0.284290  0.030442  0.023661  ... -0.191590 -0.251919 -0.098760   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "25879  0.716204  1.595793  0.310500  ... -0.342207 -0.247778 -0.122210   \n",
       "25880       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "25881       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "25882       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "25883       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "\n",
       "             53        54        55        56        57        58        59  \n",
       "0     -0.050456 -0.198736 -0.213913 -0.187095 -0.094436 -0.199338 -0.197980  \n",
       "1     -0.103755 -0.234412 -0.214502 -0.186226 -0.194537 -0.225704 -0.222353  \n",
       "2     -0.141185 -0.150112 -0.049161 -0.328302 -0.163079 -0.139322 -0.142054  \n",
       "3     -0.210834 -0.063536 -0.160048 -0.087788 -0.057035 -0.149206 -0.148674  \n",
       "4     -0.208515 -0.168009 -0.134835 -0.077329 -0.169855 -0.120925 -0.121390  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "25879 -0.209082 -0.136593 -0.066616 -0.083899 -0.005069 -0.099946 -0.089550  \n",
       "25880       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "25881       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "25882       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "25883       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[25884 rows x 60 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_f = pd.DataFrame(y_pred)\n",
    "data_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a57334af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25879</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25880</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25881</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25882</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25883</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25884 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9   ...   50   51   52  \\\n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "1      0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "2      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "25879  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0  0.0   \n",
       "25880  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "25881  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "25882  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "25883  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "        53   54   55   56   57   58   59  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  \n",
       "25879  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "25880  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "25881  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "25882  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "25883  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[25884 rows x 60 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_f2 = pd.DataFrame(y_true)\n",
    "data_f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4e39d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>완구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>여성의류</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>음료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>축산물</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>테넌트/음식점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26912</th>\n",
       "      <td>26912</td>\n",
       "      <td>담배</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26913</th>\n",
       "      <td>26913</td>\n",
       "      <td>과자</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26914</th>\n",
       "      <td>26914</td>\n",
       "      <td>커피/차</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26915</th>\n",
       "      <td>26915</td>\n",
       "      <td>조미료</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26916</th>\n",
       "      <td>26916</td>\n",
       "      <td>과일</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26917 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       session     item\n",
       "0            0       완구\n",
       "1            1     여성의류\n",
       "2            2       음료\n",
       "3            3      축산물\n",
       "4            4  테넌트/음식점\n",
       "...        ...      ...\n",
       "26912    26912       담배\n",
       "26913    26913       과자\n",
       "26914    26914     커피/차\n",
       "26915    26915      조미료\n",
       "26916    26916       과일\n",
       "\n",
       "[26917 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba0da66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve ground truths\n",
    "y_true = np.empty(shape = (dataset_train.n_sessions, dataset_train.n_items))\n",
    "for i in range(y_true.shape[0]):\n",
    "    y_true[i, :] = dataset_train.item_to_one_hot(y_test.item.values[i])\n",
    "y_true = tf.constant(y_true, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5aa400ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.24860918521881104\n",
      "Top-3 accuracy = 0.3709627687931061\n"
     ]
    }
   ],
   "source": [
    "acc       = (tf.reduce_sum(tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k = 1)) / y_true.shape[0]).numpy()\n",
    "top_3_acc = (tf.reduce_sum(tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k = 3)) / y_true.shape[0]).numpy()\n",
    "\n",
    "print(\"Accuracy = {}\".format(acc))\n",
    "print(\"Top-3 accuracy = {}\".format(top_3_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2c76b74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25884,), dtype=float32, numpy=array([1., 1., 1., ..., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOP1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715b846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:machine_TF2] *",
   "language": "python",
   "name": "conda-env-machine_TF2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
